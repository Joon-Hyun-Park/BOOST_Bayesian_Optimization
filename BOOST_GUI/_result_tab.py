import os
import tkinter as tk
from tkinter import ttk, messagebox

os.environ['OMP_NUM_THREADS'] = '1'

import numpy as np
import torch
import psutil

from BOOST import BOOST
from BayesianOptimization import BayesianOptimizer


class ResultTab(BayesianOptimizer):
    """ì‹¤í–‰ ë° ê²°ê³¼ íƒ­ (grid ë ˆì´ì•„ì›ƒ, ì¤‘ì•™ í°íŠ¸ ì œì–´, ë²„íŠ¼ í•˜ë‹¨ ë°°ì¹˜)"""

    def __init__(self, parent_notebook, main_app):
        super().__init__()
        self.main_app = main_app
        self.bg_color_2 = main_app.bg_color_2
        self.last_suggested_points = None  # ë§ˆì§€ë§‰ ì¶”ì²œ í¬ì¸íŠ¸ ì €ì¥
        self.last_param_info = None        # ë§ˆì§€ë§‰ íŒŒë¼ë¯¸í„° ì •ë³´ ì €ì¥

        # íƒ­ í”„ë ˆì„ ìƒì„± (ì˜ë¬¸ ì œëª©)
        self.frame = ttk.Frame(parent_notebook)
        parent_notebook.add(self.frame, text="Run & Results")

        self.setup_ui()

    def setup_ui(self):
        # ----- grid ë² ì´ìŠ¤ ë ˆì´ì•„ì›ƒ -----
        # row 0: ê²°ê³¼ í…ìŠ¤íŠ¸ ì˜ì—­(ìŠ¤í¬ë¡¤)  [í™•ì¥]
        # row 1: ì œì•ˆ ë¼ë²¨                [ë‚´ìš© í¬ê¸°ë§Œ]
        # row 2: ë²„íŠ¼ ë°”(ì‹¤í–‰/ì¶”ê°€)        [ê³ ì •, í•˜ë‹¨]
        self.frame.rowconfigure(0, weight=1)   # í…ìŠ¤íŠ¸ ì˜ì—­ í™•ì¥
        self.frame.rowconfigure(1, weight=0)
        self.frame.rowconfigure(2, weight=0, minsize=60)
        self.frame.columnconfigure(0, weight=1)

        # ----- ê²°ê³¼ í‘œì‹œ ì˜ì—­ (Text + Scrollbar) -----
        result_display_frame = tk.Frame(self.frame, bg=self.bg_color_2)
        result_display_frame.grid(row=0, column=0, sticky="nsew", padx=20, pady=(15, 5))

        result_display_frame.rowconfigure(0, weight=0)  # "Current Data:" ë¼ë²¨
        result_display_frame.rowconfigure(1, weight=1)  # Text í™•ì¥
        result_display_frame.columnconfigure(0, weight=1)
        result_display_frame.columnconfigure(1, weight=0)

        title_lbl = tk.Label(
            result_display_frame,
            text="Current Data:",
            font=self.main_app.label_font,
            bg=self.bg_color_2
        )
        title_lbl.grid(row=0, column=0, sticky="w")

        self.result_text = tk.Text(
            result_display_frame,
            height=15, width=70,
            font=self.main_app.button_font
        )
        result_scrollbar = ttk.Scrollbar(
            result_display_frame, orient="vertical", command=self.result_text.yview
        )
        self.result_text.configure(yscrollcommand=result_scrollbar.set)

        self.result_text.grid(row=1, column=0, sticky="nsew")
        result_scrollbar.grid(row=1, column=1, sticky="ns")

        # ----- ì œì•ˆ ë¼ë²¨ -----
        self.suggestion_label = tk.Label(
            self.frame,
            text="",
            font=self.main_app.label_font,
            bg=self.bg_color_2
        )
        self.suggestion_label.grid(row=1, column=0, sticky="", padx=20, pady=(5, 5))

        # ----- ë²„íŠ¼ ë°” (í•˜ë‹¨) -----
        button_frame = tk.Frame(self.frame, bg=self.bg_color_2)
        button_frame.grid(row=2, column=0, sticky="", pady=(5, 15))

        # ì‹¤í–‰ ë²„íŠ¼
        run_btn = tk.Button(
            button_frame,
            text="Suggest Next Points",
            command=self.run_optimization,
            font=self.main_app.button_font,
            bg=self.bg_color_2,
            takefocus=False
        )
        run_btn.grid(row=0, column=0, padx=7, pady=2)

        # êµ¬ë¶„ì„ 
        sep = tk.Frame(button_frame, width=2, height=20, bg='gray')
        sep.grid(row=0, column=1, padx=10, pady=2)

        # ì¶”ì²œ í¬ì¸íŠ¸ ì¶”ê°€ ë²„íŠ¼ (ì´ˆê¸° ë¹„í™œì„±í™”)
        self.add_points_button = tk.Button(
            button_frame,
            text="Add Recommended Points",
            command=self.add_suggested_points_to_data,
            font=self.main_app.button_font,
            bg=self.bg_color_2,
            state="disabled",
            takefocus=False
        )
        self.add_points_button.grid(row=0, column=2, padx=7, pady=2)


    def run_optimization(self):
        try:
            # ë°ì´í„° ì¶”ì¶œ
            df = self.main_app.data_tab.extract_data_only()
            partially_filled = df[df.notna().any(axis=1) & df.isna().any(axis=1)]
            if len(partially_filled) > 0:
                missing_indices = [i + 1 for i in partially_filled.index]

                messagebox.showwarning(
                    "Incomplete Data Detected",
                    f"{len(partially_filled)} row(s) are partially filled and must be completed:\n"
                    f"Rows: {', '.join(map(str, missing_indices[:10]))}"
                    f"{'...' if len(missing_indices) > 10 else ''}\n\n"
                    "Please fill in all values or delete these rows before running optimization."
                )
                return
            df = df.dropna()

            if df.empty or len(df) < 6:
                # ë°ì´í„°ê°€ ë¶€ì¡±í•  ë•Œ: LHS ìƒ˜í”Œë§
                param_config = self.main_app.param_tab.get_param_config()
                param_info = param_config["parameters"]

                # ê²°ê³¼ í‘œì‹œ
                self.result_text.delete(1.0, tk.END)
                self.result_text.insert(tk.END, "Parameter Settings:\n")
                for param in param_info:
                    self.result_text.insert(
                        tk.END,
                        f"  {param['name']}: [{param['min']}, {param['max']}], step={param['step']}\n"
                    )

                self.result_text.insert(tk.END, f"Target Variable: {param_config['y_name']}\n")

                if df.empty:
                    self.result_text.insert(tk.END, "\nNo data found. Running LHS sampling for initial exploration.\n")
                    n_samples = 10
                else:
                    self.result_text.insert(tk.END, f"\nCurrent Data ({len(df)} rows):\n", )
                    self.result_text.insert(tk.END, df.to_string(index=False))
                    self.result_text.insert(tk.END, "\n\nData is insufficient. Running LHS sampling.\n")
                    n_samples = 10 - len(df)

                # LHS ìƒ˜í”Œë§ ì‹¤í–‰
                dim = len(param_info)
                next_points = self._generate_lhs_samples(dim, n_samples, param_info=param_info)

                # ì¶”ì²œ í¬ì¸íŠ¸ì™€ íŒŒë¼ë¯¸í„° ì •ë³´ ì €ì¥
                self.last_suggested_points = next_points
                self.last_param_info = param_info
                self.add_points_button.config(state="normal")  # ë²„íŠ¼ í™œì„±í™”

                suggestion_text = (
                    f"LHS recommended points ({len(next_points)}):\n" +
                    "\n".join([
                        "Point {idx}: ".format(idx=i + 1) +
                        ", ".join([f"{param_info[j]['name']}={point[j]}" for j in range(len(point))])
                        for i, point in enumerate(next_points)
                    ])
                )
                self.suggestion_label.config(text=suggestion_text)
                return

            # Parameter ì •ë³´ ì¶”ì¶œ
            param_config = self.main_app.param_tab.get_param_config()
            param_info = param_config["parameters"]
            is_maximization = param_config.get("objective", "maximize") == "maximize"

            # ê²°ê³¼ í‘œì‹œ
            self.result_text.delete(1.0, tk.END)
            self.result_text.insert(tk.END, "Parameter Settings:\n")
            for param in param_info:
                self.result_text.insert(
                    tk.END,
                    f"  {param['name']}: [{param['min']}, {param['max']}], step={param['step']}\n"
                )

            self.result_text.insert(tk.END, f"Target Variable: {param_config['y_name']}\n")
            self.result_text.insert(tk.END, f"\nCurrent Data ({len(df)} rows):\n")
            self.result_text.insert(tk.END, df.to_string(index=False))

            # GUI ë°ì´í„°ì—ì„œ X, Y ì¶”ì¶œ
            train_x_list, train_y_list = [], []
            for _, row in df.iterrows():
                x_values = [row.iloc[i] for i in range(len(param_info))]
                train_x_list.append(x_values)
                y_value = row.iloc[-1]
                train_y_list.append(y_value)

            # torch tensorë¡œ ë³€í™˜
            device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
            train_x = torch.tensor(train_x_list, dtype=torch.double, device=device)
            train_y = torch.tensor(train_y_list, dtype=torch.double, device=device)

            # ìµœëŒ€í™” ë¬¸ì œë©´ ë¶€í˜¸ ë³€ê²½ (ë‚´ë¶€ ìµœì†Œí™” í˜•íƒœë¡œ)
            if is_maximization:
                train_y = -train_y
                self.result_text.insert(tk.END, f"\n\nObjective: maximize {param_config['y_name']}\n")
            else:
                self.result_text.insert(tk.END, f"\n\nObjective: minimize {param_config['y_name']}\n")

            # candidate points ìƒì„± (grid)
            candidate_points = []
            for d, param in enumerate(param_info):
                grid = []
                current = param['min']
                while current <= param['max']:
                    grid.append(current)
                    current = round(current + param['step'], 10)
                candidate_points.append(torch.tensor(grid, dtype=torch.double, device=device))


            # â”€â”€ ğŸ’¡ í›„ë³´ì  ê°œìˆ˜ ë° ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì²´í¬ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            num_candidates = 1
            for grid in candidate_points:
                num_candidates *= len(grid)

            dim = len(candidate_points)
            expected_mem = num_candidates * dim * 8  # GB ë‹¨ìœ„ (float64 ê¸°ì¤€)
            mem = psutil.virtual_memory()

            print(expected_mem/ (1024**3))
            print(mem.total/ (1024**3))

            used_ratio = expected_mem / mem.total  # ì „ì²´ RAM ëŒ€ë¹„ ì˜ˆìƒ ë¹„ìœ¨

            if used_ratio >= 0.2:
                messagebox.showwarning(
                    "Memory Warning",
                    f"Candidate points may require ~{expected_mem:.2f} GB "
                    f"({used_ratio * 100:.1f}% of total RAM).\n\n"
                    "This could slow down or freeze the program. "
                    "Consider reducing parameter ranges or step size."
                )
                return
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

            candidate_x = torch.cartesian_prod(*candidate_points).to(device)

            # ì´ë¯¸ í‰ê°€ëœ ì ë“¤ ì œê±°
            mask = ~torch.any(torch.cdist(candidate_x, train_x) < 1e-5, dim=1)
            filtered_candidate_x = candidate_x[mask]

            # ë°ì´í„° ìˆ˜ ì²´í¬
            if len(train_x) < 6:
                messagebox.showwarning("Insufficient Data", "At least 6 data points are required to use BOOST.")
                return

            if len(filtered_candidate_x) == 0:
                messagebox.showinfo("Optimization Complete", "All possible combinations have already been evaluated!")
                return

            # ì§„í–‰ ìƒí™© ì¶œë ¥
            self.result_text.insert(tk.END, "\nRunning Bayesian Optimization...\n")
            self.result_text.insert(tk.END, "Searching for the best kernelâ€“acquisition pair...\n")
            self.result_text.update()  # UI ì¦‰ì‹œ ì—…ë°ì´íŠ¸

            boost = BOOST(device=device)
            kernel_type, acquisition_type = boost.get_kernel_acq(train_x=train_x, train_y=train_y)

            self.result_text.insert(tk.END, f"Selected kernel: {kernel_type.value}\n")
            self.result_text.insert(tk.END, f"Selected acquisition: {acquisition_type.value}\n")

            next_point, _, prediction_mean, prediction_var = self.get_next_point(
                train_x=train_x,
                train_y=train_y,
                filtered_candidate_x=filtered_candidate_x,
                kernel_type=kernel_type,
                acquisition_type=acquisition_type
            )

            prediction_std = np.sqrt(prediction_var)

            # ìµœëŒ€í™” ì›ë³µ
            if is_maximization:
                prediction_mean = -prediction_mean

            # 67% ì‹ ë¢°êµ¬ê°„
            lower_bound = prediction_mean - prediction_std
            upper_bound = prediction_mean + prediction_std

            # next_point ë³€í™˜
            next_point_cpu = next_point.cpu().numpy().flatten()
            next_point_list = [round(float(val), 4) for val in next_point_cpu]

            # ê²°ê³¼ í‘œì‹œ
            self.result_text.insert(tk.END, "\n=== Prediction ===\n")
            point_str = ", ".join([f"{param_info[i]['name']}={next_point_list[i]}"
                                   for i in range(len(next_point_list))])
            self.result_text.insert(tk.END, f"Recommended Point: {point_str}\n")
            self.result_text.insert(tk.END, f"Predicted {param_config['y_name']}: {prediction_mean:.4f}\n")
            self.result_text.insert(tk.END, f"67% CI: [{lower_bound:.4f}, {upper_bound:.4f}]\n")
            self.result_text.insert(tk.END, f"Std. (Â±1Ïƒ): {prediction_std:.4f}\n")

            suggestion_text = (
                "Suggested Point: " +
                point_str +
                f"\nPredicted {param_config['y_name']}: [{lower_bound:.4f}, {upper_bound:.4f}]"
            )
            self.suggestion_label.config(text=suggestion_text)

            # ë‹¨ì¼ í¬ì¸íŠ¸ë„ ë¦¬ìŠ¤íŠ¸ë¡œ ì €ì¥
            self.last_suggested_points = [next_point_list]
            self.last_param_info = param_info
            self.add_points_button.config(state="normal")

        except Exception as e:
            messagebox.showerror("Execution Error", str(e))

    def add_suggested_points_to_data(self):
        """ì¶”ì²œëœ í¬ì¸íŠ¸ë“¤ì„ ë°ì´í„° íƒ­ì— ì¶”ê°€"""
        if self.last_suggested_points and self.last_param_info:
            self.main_app.data_tab.add_suggested_points(self.last_suggested_points, self.last_param_info)
            self.add_points_button.config(state="disabled")  # ì¶”ê°€ í›„ ë¹„í™œì„±í™”
        else:
            messagebox.showwarning("Warning", "There are no recommended points to add.")

    def _generate_lhs_samples(self, dim, n_samples, param_info=None):
        """LHS for discrete grid points."""
        import numpy as np
        from itertools import product
        import torch
        import random

        # ê¸°ì¡´ í‰ê°€ëœ ì ë“¤ í™•ì¸
        evaluated_set = set()
        df = self.main_app.data_tab.extract_data_only()
        if not df.empty:
            for _, row in df.iterrows():
                point = tuple(np.round([row.iloc[i] for i in range(dim)], 6))
                evaluated_set.add(point)

        generated_samples = set()

        # ê° ì°¨ì›ë³„ grid point ê°œìˆ˜
        dim_grid_sizes = []
        for d in range(dim):
            param = param_info[d] if param_info else None
            grid_size = int(round((param['max'] - param['min']) / param['step'], 6)) + 1
            dim_grid_sizes.append(grid_size)

        max_possible_samples = min(dim_grid_sizes)
        actual_n_samples = min(n_samples, max_possible_samples)
        n_samples = max(min(n_samples, max_possible_samples), 6)

        while len(generated_samples) < n_samples:
            # LHS candidate in each dim
            lhs_points = []
            for d in range(dim):
                param = param_info[d] if param_info else None
                grid_points = []
                current = param['min']
                while current <= param['max']:
                    grid_points.append(current)
                    current = round(current + param['step'], 10)
                grid_points = torch.tensor(grid_points, dtype=torch.double)

                n_grid_actual = len(grid_points)
                lhs_step = max(1, (n_grid_actual - 1) // (actual_n_samples - 1))
                lhs_start = ((n_grid_actual - 1) - lhs_step * (actual_n_samples - 1)) // 2
                dim_points = [grid_points[lhs_start + i * lhs_step].item() for i in range(actual_n_samples)]
                random.shuffle(dim_points)
                lhs_points.append(dim_points)

            # ì¡°í•© ìˆ˜ê°€ ì ì–´ì„œ LHSê°€ ë¬´ì˜ë¯¸í•œ ê²½ìš° â†’ ê°€ëŠ¥í•œ ì¡°í•©ì—ì„œ ëœë¤ ìƒ˜í”Œ
            if n_samples >= max_possible_samples ** d:
                grid_lists = []
                for param in param_info:
                    grid = []
                    current = param['min']
                    while current <= param['max']:
                        grid.append(round(current, 6))
                        current = round(current + param['step'], 10)
                    grid_lists.append(grid)

                all_combinations = list(product(*grid_lists))
                all_combinations = [p for p in all_combinations if tuple(np.round(p, 6)) not in evaluated_set]

                available = len(all_combinations)
                if available < n_samples:
                    messagebox.showwarning(
                        "Insufficient Samples",
                        f"Requested {n_samples} samples, but only {available} combinations are available.\n"
                        f"Only {available} will be generated."
                    )
                else:
                    messagebox.showinfo(
                        "LHS Fallback",
                        "LHS is not suitable here; random sampling from all available combinations will be used."
                    )

                random.shuffle(all_combinations)
                return [list(p) for p in all_combinations[:n_samples]]

            else:
                # add to generated_samples
                new_points = list(zip(*lhs_points))
                for point in new_points:
                    point_tuple = tuple(np.round(point, 6))
                    if (point_tuple not in evaluated_set) and (point_tuple not in generated_samples):
                        generated_samples.add(point_tuple)
                    if len(generated_samples) >= n_samples:
                        break

        return [list(point) for point in list(generated_samples)]
